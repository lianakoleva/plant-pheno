{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a44a3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/archive/v0.10.0.zip\" to /home/liana_e_koleva/.cache/torch/hub/v0.10.0.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e11140b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_suffix(input_string, suffix):\n",
    "    if suffix and input_string.endswith(suffix):\n",
    "        return input_string[:-len(suffix)]\n",
    "    return input_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7aae4de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ein2': ['ara2013_plant001', 'ara2013_plant002', 'ara2013_plant006', 'ara2013_plant008', 'ara2013_plant012', 'ara2013_plant014', 'ara2013_plant019', 'ara2013_plant024', 'ara2013_plant028', 'ara2013_plant032', 'ara2013_plant035', 'ara2013_plant042', 'ara2013_plant046', 'ara2013_plant049', 'ara2013_plant051', 'ara2013_plant054', 'ara2013_plant057', 'ara2013_plant064', 'ara2013_plant069', 'ara2013_plant072', 'ara2013_plant074', 'ara2013_plant079', 'ara2013_plant081', 'ara2013_plant087', 'ara2013_plant088', 'ara2013_plant096', 'ara2013_plant097', 'ara2013_plant104', 'ara2013_plant106', 'ara2013_plant109', 'ara2013_plant112', 'ara2013_plant114', 'ara2013_plant118', 'ara2013_plant121', 'ara2013_plant123', 'ara2013_plant130', 'ara2013_plant140', 'ara2013_plant149', 'ara2013_plant158'], 'ctr': ['ara2013_plant003', 'ara2013_plant007', 'ara2013_plant009', 'ara2013_plant010', 'ara2013_plant015', 'ara2013_plant017', 'ara2013_plant020', 'ara2013_plant025', 'ara2013_plant029', 'ara2013_plant033', 'ara2013_plant037', 'ara2013_plant040', 'ara2013_plant047', 'ara2013_plant058', 'ara2013_plant062', 'ara2013_plant065', 'ara2013_plant070', 'ara2013_plant078', 'ara2013_plant082', 'ara2013_plant090', 'ara2013_plant094', 'ara2013_plant098', 'ara2013_plant102', 'ara2013_plant110', 'ara2013_plant119', 'ara2013_plant124', 'ara2013_plant127', 'ara2013_plant133', 'ara2013_plant143', 'ara2013_plant150', 'ara2013_plant153', 'ara2013_plant161'], 'Col-0': ['ara2013_plant004', 'ara2013_plant016', 'ara2013_plant021', 'ara2013_plant023', 'ara2013_plant031', 'ara2013_plant039', 'ara2013_plant043', 'ara2013_plant045', 'ara2013_plant052', 'ara2013_plant059', 'ara2013_plant061', 'ara2013_plant066', 'ara2013_plant068', 'ara2013_plant075', 'ara2013_plant077', 'ara2013_plant083', 'ara2013_plant085', 'ara2013_plant091', 'ara2013_plant093', 'ara2013_plant099', 'ara2013_plant101', 'ara2013_plant107', 'ara2013_plant115', 'ara2013_plant117', 'ara2013_plant126', 'ara2013_plant132', 'ara2013_plant134', 'ara2013_plant142', 'ara2013_plant144', 'ara2013_plant152', 'ara2013_plant154', 'ara2013_plant156', 'ara2013_plant160', 'ara2013_plant162'], 'pgm': ['ara2013_plant005', 'ara2013_plant013', 'ara2013_plant022', 'ara2013_plant027', 'ara2013_plant030', 'ara2013_plant036', 'ara2013_plant038', 'ara2013_plant041', 'ara2013_plant044', 'ara2013_plant050', 'ara2013_plant053', 'ara2013_plant056', 'ara2013_plant060', 'ara2013_plant063', 'ara2013_plant067', 'ara2013_plant073', 'ara2013_plant076', 'ara2013_plant080', 'ara2013_plant084', 'ara2013_plant089', 'ara2013_plant092', 'ara2013_plant100', 'ara2013_plant105', 'ara2013_plant108', 'ara2013_plant113', 'ara2013_plant116', 'ara2013_plant122', 'ara2013_plant125', 'ara2013_plant135', 'ara2013_plant137', 'ara2013_plant138', 'ara2013_plant145', 'ara2013_plant147', 'ara2013_plant163', 'ara2013_plant165'], 'adh1': ['ara2013_plant011', 'ara2013_plant018', 'ara2013_plant026', 'ara2013_plant034', 'ara2013_plant048', 'ara2013_plant055', 'ara2013_plant071', 'ara2013_plant086', 'ara2013_plant095', 'ara2013_plant103', 'ara2013_plant111', 'ara2013_plant120', 'ara2013_plant128', 'ara2013_plant129', 'ara2013_plant131', 'ara2013_plant136', 'ara2013_plant139', 'ara2013_plant141', 'ara2013_plant146', 'ara2013_plant148', 'ara2013_plant151', 'ara2013_plant155', 'ara2013_plant157', 'ara2013_plant159', 'ara2013_plant164']}\n",
      "already exists\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "import csv\n",
    "import glob\n",
    "import os \n",
    "import shutil\n",
    "\n",
    "# os.chdir(r\"Plant_Phenotyping_Datasets/Plant/Ara2013-RPi\") # directory in question\n",
    "\n",
    "# construct dictionary of labels\n",
    "# Metadata.csv contains labels with keys ara2013_plant000 to ara2013_plant165\n",
    "labels = dict()\n",
    "with open(\"Metadata.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    for i, line in enumerate(reader):\n",
    "        line = line[0].split(',') # split string into categories\n",
    "        line[1] = line[1].lstrip() # clear whitespace\n",
    "        if line[1] not in labels:\n",
    "            labels[line[1]] = [line[0]]\n",
    "        else:   \n",
    "            labels[line[1]].append(line[0])\n",
    "print(labels)\n",
    "        \n",
    "\n",
    "for label in labels:\n",
    "    try:\n",
    "        os.mkdir(label)\n",
    "    except FileExistsError:\n",
    "        print(\"already exists\")\n",
    "        \n",
    "    for pngname in labels[label]:\n",
    "        pngfile = pngname + \"_rgb.png\"\n",
    "        shutil.copy(pngfile, label)\n",
    "            \n",
    "\n",
    "# image names ara2013_plant000_rgb.png to ara2013_plant165_rgb.png\n",
    "# widths = []\n",
    "# heights = []\n",
    "# min_w = 1000\n",
    "# min_h = 1000\n",
    "# for img_filename in glob.glob(\"*.png\"):\n",
    "#     name = remove_suffix(img_filename, \"_rgb.png\")\n",
    "#     img = Image.open(img_filename)\n",
    "    \n",
    "#     label = labels[name] \n",
    "  \n",
    "#     # get width and height\n",
    "#     width = img.width\n",
    "#     height = img.height\n",
    "#     widths.append(width)\n",
    "#     heights.append(height)\n",
    "#     print(\"width: \", width)\n",
    "#     print(\"height: \", height)\n",
    "    \n",
    "#     if width < min_w:\n",
    "#         min_w = width\n",
    "#     if height < min_h:\n",
    "#         min_h = height\n",
    "#     if width == 36:\n",
    "#         print(img_filename)\n",
    "#         print(\"width: \", width)\n",
    "#         print(\"height: \", height)\n",
    "#     if height == 37:\n",
    "#         print(img_filename)\n",
    "#         print(\"width: \", width)\n",
    "#         print(\"height: \", height)\n",
    "    \n",
    "# print(min(widths))\n",
    "# print(min(heights))\n",
    "    \n",
    "  \n",
    "    # to access the genotype, use label[name]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f96babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(classifier, criterion, optimizer):\n",
    "    classifier.train()\n",
    "    loss_ = 0.0\n",
    "    losses = []\n",
    "    for img_filename in glob.glob(\"*.png\"):\n",
    "        # how to get image from img_filename?\n",
    "        image = img_filename.to(device)\n",
    "        \n",
    "        # get label from name\n",
    "        name = remove_suffix(img_filename, \"_rgb.png\")\n",
    "        label = labels[name].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits.classifier(images)\n",
    "        loss = criterion(logits, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss)\n",
    "        \n",
    "    return torch.stack(losses).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9598a8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier(test_loader, classifier, criterion, print_ind_classes=True, print_total=True):\n",
    "    classifier.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        y_true = np.zeros((0,21))\n",
    "        y_score = np.zeros((0,21))\n",
    "        for i, (images, labels) in enumerate(test_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            logits = classifier(images)\n",
    "            y_true = np.concatenate((y_true, labels.cpu().numpy()), axis=0)\n",
    "            y_score = np.concatenate((y_score, logits.cpu().numpy()), axis=0)\n",
    "            loss = criterion(logits, labels)\n",
    "            losses.append(loss.item())\n",
    "        aps = []\n",
    "        # ignore first class which is background\n",
    "        for i in range(1, y_true.shape[1]):\n",
    "            ap = average_precision_score(y_true[:, i], y_score[:, i])\n",
    "            if print_ind_classes:\n",
    "                print('-------  Class: {:<12}     AP: {:>8.4f}  -------'.format(VOC_CLASSES[i], ap))\n",
    "            aps.append(ap)\n",
    "        \n",
    "        mAP = np.mean(aps)\n",
    "        test_loss = np.mean(losses)\n",
    "        if print_total:\n",
    "            print('mAP: {0:.4f}'.format(mAP))\n",
    "            print('Avg loss: {}'.format(test_loss))\n",
    "        \n",
    "    return mAP, test_loss, aps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "018e6a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train, val, test_frequency, num_epochs):\n",
    "    plt.plot(train, label=\"train\")\n",
    "    indices = [i for i in range(num_epochs) if ((i+1)%test_frequency == 0 or i ==0)]\n",
    "    plt.plot(indices, val, label=\"val\")\n",
    "    plt.title(\"Loss Plot\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_mAP(train, val, test_frequency, num_epochs):\n",
    "    indices = [i for i in range(num_epochs) if ((i+1)%test_frequency == 0 or i ==0)]\n",
    "    plt.plot(indices, train, label=\"train\")\n",
    "    plt.plot(indices, val, label=\"val\")\n",
    "    plt.title(\"mAP Plot\")\n",
    "    plt.ylabel(\"mAP\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend()\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "921b9e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(classifier, num_epochs, train_loader, val_loader, criterion, optimizer, test_frequency=5):\n",
    "    train_losses = []\n",
    "    train_mAPs = []\n",
    "    val_losses = []\n",
    "    val_mAPs = []\n",
    "\n",
    "    for epoch in range(1,num_epochs+1):\n",
    "        print(\"Starting epoch number \" + str(epoch))\n",
    "        train_loss = train_classifier(train_loader, classifier, criterion, optimizer)\n",
    "        train_losses.append(train_loss)\n",
    "        print(\"Loss for Training on Epoch \" +str(epoch) + \" is \"+ str(train_loss))\n",
    "        if(epoch%test_frequency==0 or epoch==1):\n",
    "            mAP_train, _, _ = test_classifier(train_loader, classifier, criterion, False, False)\n",
    "            train_mAPs.append(mAP_train)\n",
    "            mAP_val, val_loss, _ = test_classifier(val_loader, classifier, criterion)\n",
    "            print('Evaluating classifier')\n",
    "            print(\"Mean Precision Score for Testing on Epoch \" +str(epoch) + \" is \"+ str(mAP_val))\n",
    "            val_losses.append(val_loss)\n",
    "            val_mAPs.append(mAP_val)\n",
    "    \n",
    "    return classifier, train_losses, val_losses, train_mAPs, val_mAPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "abd8057e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2893/387725545.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n\u001b[0m\u001b[1;32m      5\u001b[0m                                      std= [0.229, 0.224, 0.225]) # is this custom to the mp3 data? \n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms.transforms import RandomResizedCrop\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std= [0.229, 0.224, 0.225]) # is this custom to the mp3 data? \n",
    "\n",
    "# you should use the torchvision.transforms module to try adding \n",
    "# random resized crops and horizontal flips of the input data\n",
    "\n",
    "# check transforms.RandomResizedCrop and transforms.RandomHorizontalFlip \n",
    "\n",
    "# feel free to apply more transforms for data augmentation \n",
    "# which can lead to better performance\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "            transforms.Resize(227),\n",
    "            transforms.CenterCrop(227),\n",
    "            transforms.RandomResizedCrop(227), # suggested add\n",
    "            transforms.RandomHorizontalFlip(), # suggested add\n",
    "            # transforms.RandomRotation(180), # self add\n",
    "            transforms.ToTensor(),\n",
    "            normalize\n",
    "        ])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "            transforms.Resize(227),\n",
    "            transforms.CenterCrop(227),\n",
    "            transforms.RandomResizedCrop(227), # suggested add\n",
    "            transforms.RandomHorizontalFlip(), # suggested add\n",
    "            # transforms.RandomRotation(180), # self add\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "ds_train = VocDataset('VOCdevkit_2007/VOC2007/','train',train_transform)\n",
    "ds_val = VocDataset('VOCdevkit_2007/VOC2007/','val',test_transform)\n",
    "ds_test = VocDataset('VOCdevkit_2007/VOC2007test/','test', test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08a4a5e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2893/2039363305.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m train_loader = torch.utils.data.DataLoader(dataset=ds_train,\n\u001b[0m\u001b[1;32m      6\u001b[0m                                                \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                                \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ds_train' is not defined"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "test_frequency = 5\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=ds_train,\n",
    "                                               batch_size=batch_size, \n",
    "                                               shuffle=True,\n",
    "                                               num_workers=1)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=ds_val,\n",
    "                                               batch_size=batch_size, \n",
    "                                               shuffle=True,\n",
    "                                               num_workers=1)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=ds_test,\n",
    "                                               batch_size=batch_size, \n",
    "                                               shuffle=False,\n",
    "                                               num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2b1d0b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2893/3261218116.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# classifier.load_state_dict(torch.load('voc_my_best_classifier.pth'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiLabelSoftMarginLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# instead of plain SGD, you may want to add a learning rate schedule, add momentum,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "classifier = model\n",
    "# classifier.load_state_dict(torch.load('voc_my_best_classifier.pth'))\n",
    "\n",
    "criterion = nn.MultiLabelSoftMarginLoss()\n",
    "\n",
    "# instead of plain SGD, you may want to add a learning rate schedule, add momentum, \n",
    "# or use one of the other optimizers you have learned about like Adam\n",
    "# check the torch.optim package for other optimizers\n",
    "# optimizer = torch.optim.SGD(classifier.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-4)\n",
    "\n",
    "classifier, train_losses, val_losses, train_mAPs, val_mAPs = train(classifier, num_epochs, train_loader, val_loader, criterion, optimizer, test_frequency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "90000398",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2893/1328662703.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_frequency\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplot_mAP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mAPs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_mAPs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_frequency\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_losses' is not defined"
     ]
    }
   ],
   "source": [
    "plot_losses(train_losses, val_losses, test_frequency, num_epochs)\n",
    "plot_mAP(train_mAPs, val_mAPs, test_frequency, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af924e23",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2893/1446557333.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmAP_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_aps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmAP_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_classifier' is not defined"
     ]
    }
   ],
   "source": [
    "mAP_test, test_loss, test_aps = test_classifier(test_loader, classifier, criterion)\n",
    "print(mAP_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220d9190",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(classifier.state_dict(), './voc_my_best_classifier.pth')\n",
    "output_submission_csv('my_solution.csv', test_aps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
